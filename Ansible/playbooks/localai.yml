- hosts: tag_role_Master
  become: true
  tasks:
    # - name: Install Piplibrary
    #   apt:
    #     name: python3-pip
    #     state: present

    # - name: Install Kubernetes Python library
    #   pip:
    #     name: kubernetes
    #     state: present
      
    - name: Create namespace
      kubernetes.core.k8s:
        state: present
        kubeconfig: /home/ubuntu/.kube/config
        definition:
          apiVersion: v1
          kind: Namespace
          metadata:
            name: k8sgpt-operator-system
    
  
    # - name: Create storageclass
    #   kubernetes.core.k8s:
    #     state: present
    #     kubeconfig: /home/ubuntu/.kube/config
    #     definition:
    #       apiVersion: storage.k8s.io/v1
    #       kind: StorageClass
    #       metadata:
    #         name: standard-ebs
    #       provisioner: kubernetes.io/aws-ebs
    #       parameters:
    #         type: gp2
    #         fsType: ext4
    #         encrypted: "false"
    #       reclaimPolicy: Delete
    #       volumeBindingMode: WaitForFirstConsumer
    - name: Create PV
      kubernetes.core.k8s:
        state: present
        kubeconfig: /home/ubuntu/.kube/config
        definition:
          apiVersion: v1
          kind: PersistentVolume
          metadata:
            name: ebs-localai-vol
          spec:
            capacity:
              storage: 100Gi
            accessModes:
              - ReadWriteOnce
            persistentVolumeReclaimPolicy: Retain
            storageClassName: manual
            csi:
              driver: ebs.csi.aws.com
              volumeHandle: "{{ volume_id }}"  # Replace <volume-id> with the actual EBS volume ID
              fsType: ext4


    - name: Create pvc
      kubernetes.core.k8s:
        state: present
        kubeconfig: /home/ubuntu/.kube/config
        definition:
          apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            name: model-pvc
            namespace: k8sgpt-operator-system
          spec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 40Gi
            storageClassName: manual

    - name: Create localai deployment
      kubernetes.core.k8s:
        state: present
        kubeconfig: /home/ubuntu/.kube/config
        definition:
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: local-ai-deployment
            namespace: k8sgpt-operator-system
          spec:
            replicas: 1
            selector:
              matchLabels:
                app: local-ai
            template:
              metadata:
                labels:
                  app: local-ai
              spec:
                initContainers:
                - name: download-models
                  image: alpine
                  command:
                  - /bin/sh
                  - -c
                  - >
                    apk add --no-cache curl &&
                    if [ ! -f /models/ggml-gpt4all-j.bin ]; then
                      curl -o /models/ggml-gpt4all-j.bin https://gpt4all.io/models/ggml-gpt4all-j.bin;
                    else
                      echo "Model file already exists";
                    fi
                  volumeMounts:
                  - mountPath: /models
                    name: model-volume
                containers:
                - name: local-ai
                  image: quay.io/go-skynet/local-ai:master-ffmpeg-core
                  env:
                  - name: THREADS
                    value: "4"
                  - name: CONTEXT_SIZE
                    value: "512"
                  - name: GALLERIES
                    value: '[{"name":"model-gallery", "url":"github:go-skynet/model-gallery/index.yaml"}, {"url": "github:go-skynet/model-gallery/huggingface.yaml","name":"huggingface"}]'
                  - name: PRELOAD_MODELS
                    value: '[{ "id": "huggingface@thebloke__open-llama-13b-open-instruct-ggml__open-llama-13b-open-instruct.ggmlv3.q3_k_m.bin", "name": "gpt-3.5-turbo", "overrides": { "f16": true, "mmap": true }}]'
                  - name: MODELS_PATH
                    value: "/models"
                  volumeMounts:
                  - mountPath: /models
                    name: model-volume
                volumes:
                - name: model-volume
                  persistentVolumeClaim:
                    claimName: model-pvc